---
title: 'Deep Forest: Towards an Alternative to Deep Neural Networks (阅读笔记)'
date: 2017-06-30
permalink: /posts/2017/06/blog-post-6/
tags:
  - 深度森林
  - gcForest
  - 深度学习
---

**This is an original article. Please indicate reference if reproduced.**  

## Introduction

首先，文中阐述了深度神经网络的一些缺陷，主要分为三个方面：
- 数据
  - 有监督的深度学习方法通常都需要大量的数据用来训练，即使训练出来的模型是应用在小规模数据的任务上。
  - 即使是在获得大量数据的情况下，通常也会面临数据标注的问题，因为大量数据的标注通常花费高昂。
- 运算性能
  - 深度神经网络是非常复杂的模型，运算时需要大量的计算资源。
  - 太多的超参数。
- 训练  
  深度神经网络的训练非常讲究技巧，需要多种配置的组合，但是对其进行理论分析却十分困难。

但是，深度神经网络有一个非常重要的能力：**表征学习**。值得注意的是，为了运用大量数据，学习模型的容量通常都很大，这里尤其是指“**深度**”。因此，作者推测可以将这种性质用到其他合适的学习模型上，也许能达到相当的效果。所以，本文就将神经元这个基本结构替换成的了决策树。

## Cascade Forest Structure

如图1所示，级联森林由一层一层的随机森林构成，特征经过每一层随机森林处理，传到下一层。下面以图1为例进行说明。
- 对于每一层
  - 蓝色的是两个完全随机树森林
    - 每个完全随机树森林由500棵完全随机树构成
    - 在每个结点上随机选择一个特征
    - 每棵决策树生成到每个叶结点只包含相同类的实例
  - 黑色的是两个随机森林
    - 每个随机森林由500棵随机树构成
    - 随机选择$\sqrt{d}$个输入特征作为候选
    - 当Gini系数达到最优时停止树的生成
  - 以三个类别为例，将最后一层森林的概率结果求平均，然后取最大值，得到最终结果

![图1 级联森林结构说明](https://user-images.githubusercontent.com/7368805/27729519-c8803c44-5db8-11e7-83a9-42d45250aeb7.png)

- 对于每个森林，仍然以三个类别为例
  - 每棵决策树可以得到某个实例分别属于三个类别的概率
  - 将所有决策树的概率向量求平均，作为其对应森林的类别向量
- 验证(Validation)
  - 每个森林在输出最终结果前，会使用交叉验证的方法，得到最优的类别向量
  - 每拓展一层，都会对所有的级联结构进行一次验证，若结果并没有提升，则不再增加层数

![图2 类别向量生成说明](https://user-images.githubusercontent.com/7368805/27745062-892bfa6a-5df4-11e7-8b72-a5f8d99723a5.png)

## Multi-Grained Scanning

本部分主要讲的是在原始数据集上提取特征的的过程，图3的上半部分原始数据是一个400维的向量，下半部分的原始数据类型是二维矩阵，我们以上半部分400维的向量为例。首先，使用100维的滑窗，以步长为1进行扫描，得到301个100纬的实例。再将这301个实例分别塞进森林A和森林B，则，分别得到301个3维向量，分别对应三个类别的概率。将这些向量堆叠起来，则构成了原始数据的特征，这些特征将会被输入到下一层的级联森林。

![图3 使用滑窗扫描来重新表示特征](https://user-images.githubusercontent.com/7368805/27745892-b46c069a-5df7-11e7-9655-0ba18ad33c94.png)

## Overall Procedure and Hyper-Parameters

图4所示为整个gcForest的处理流程。首先将一个400维的原始数据经由Multi-Grained Scanning阶段提取特征，这里选取了三种尺度的滑窗，分别生成三种尺度下的特征向量，第一种尺度下的特征除直接作为级联森林的输入外，还会与级联森林第1层(4,7,...)的输出拼接在一起作为第2层(5,8,...)的输入。第二种尺度下的特征，则与级联森林第2层(5,8,...)的输出拼接在一起作为第3层(6,9,...)的输入。第三种尺度下的特征，则与级联森林第3层(6,9,...)的输出拼接在一起作为第4层(7,10,...)的输入。将最后一层的结果求平均，取最大值，得到最终的预测结果。

![图4 gcForest的流程图](https://user-images.githubusercontent.com/7368805/27746155-aaab63c0-5df8-11e7-8504-b7f777c74aec.png)

## Experiments

- gcForest分别在图像分类(MNIST)，人脸识别(ORL)，音乐分类(GTZAN)，手势运动识别(sEMG)，情感分类(IMDB)，低纬度数据(UCI-dataset)等任务中进行了实验，实验结果展现出不亚于深度神经网络的表现。
- gcForest的主要超参数是每层森林的个数，以及每个森林中树的个数，需要配置的超参数远远小于神经网络。
- 当特征具有空间关系或者连续性关系的时候，使用多尺度的滑窗会取得更好的效果。
- 在IMDB数据集上的性能分析，
  - computing units：2 Intel E5 2695 v4 CPUs
  - gcForest: 40 min
  - MLP: 77.5 min

## Conclusion
（笔者个人总结）
- 作者利用深度神经网络中的深度思想，构造级联森林结构，思想上具有一定的高度，但是与相关工作相比，并不能说是非常创新。
- 对于idea漫天飞的小白笔者来说，有两点值得学习的地方。
  - idea转化为论文还有很长的路，一定要想清楚细节的地方。
  - 对于深度学习这种比较庞大的模型，构建起来是需要一定的代码。这是需要下功夫的地方。

  ---------------------------------------------------
  **如有任何相关问题欢迎评论或者邮件讨论<15120452@bjtu.edu.cn>**
